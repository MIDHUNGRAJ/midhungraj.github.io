---
title: 'Understanding Vectors in Linear Algebra with Python'
date: 2023-02-05
permalink: /posts/2023/02/blog-post-5/
tags:
  - Linear Algebra
  - Beginner
  - Mathematics
  - Numerical Computing
---


# Title: Understanding Vectors in Linear Algebra with Python

## Introduction

Linear algebra is a cornerstone of mathematics, data science, and machine learning. At its core, linear algebra deals with vectors and matrices. Vectors, in particular, are fundamental structures that represent quantities having both magnitude and direction. In this beginner-friendly guide, we’ll explore the concept of vectors, how to perform basic operations on them, and how to use Python (with the NumPy library) to make working with vectors more intuitive and efficient.

---

### What is a Vector?

A vector is an ordered list of numbers. In two dimensions, it can be thought of as an arrow pointing from the origin to a point (x, y). In higher dimensions, vectors are similarly defined, with coordinates in 3D (x, y, z), 4D, or more.

Examples of vectors:

- 2D vector: `[3, 4]`
- 3D vector: `[1, 2, 5]`

Vectors have a variety of applications, including:
- Representing spatial points or movements.
- Defining directions in machine learning algorithms.
- Modeling forces in physics.

#### Mathematical vs. Python Vectors

In mathematics, vectors are typically represented as column vectors or row vectors, with dimensions explicitly indicated. For example, a 3-dimensional column vector might be written as:

$$
\begin{bmatrix} 1 \\ 2 \\ 3 \end{bmatrix}
$$

In Python, vectors are represented using arrays. NumPy, a popular library for numerical computing, uses 1-dimensional arrays for vectors:

```python
import numpy as np
vec = np.array([1, 2, 3])  # Orientationless 1D array.
```

### Python Arrays vs. Mathematical Vectors

1. **Dimension Differences**: In mathematics, the dimensionality of a vector refers to its number of elements. In Python, a vector is treated as a one-dimensional array (shape `(n,)`) unless explicitly reshaped into a row `(1, n)` or column `(n, 1)` vector.

2. **Row vs. Column Representation**: Consider the following examples:

```python
asList = [1, 2, 3]         # Python list
asArray = np.array([1, 2, 3])  # 1D array
rowVec = np.array([[1, 2, 3]]) # Row vector (1, 3)
colVec = np.array([[1], [2], [3]]) # Column vector (3, 1)

print(f'asList:  {np.shape(asList)}')
print(f'asArray: {asArray.shape}')
print(f'rowVec:  {rowVec.shape}')
print(f'colVec:  {colVec.shape}')
```

**Output:**
```
asList:  (3,)
asArray: (3,)
rowVec:  (1, 3)
colVec:  (3, 1)
```

This distinction is important, especially when performing matrix operations, where the orientation (row vs. column) can affect results. Although a 1D array in NumPy looks like a row vector when printed, it does not carry explicit row or column orientation. Understanding this nuance helps prevent errors and aids in debugging.

---

### Creating Vectors in Python

Using Python’s NumPy library makes it easy to create and manipulate vectors. First, install NumPy if you haven’t already:

```bash
pip install numpy
```

Then, import it into your code:

```python
import numpy as np
```

Let’s create a simple vector:

```python
vector_2d = np.array([3, 4])
vector_3d = np.array([1, 2, 5])

print("2D Vector:", vector_2d)
print("3D Vector:", vector_3d)
```

**Output:**
```
2D Vector: [3 4]
3D Vector: [1 2 5]
```

---

### Basic Operations on Vectors

#### 1. **Vector Addition**

When you add two vectors, you add their corresponding components:

```python
vec1 = np.array([1, 2])
vec2 = np.array([3, 4])

result = vec1 + vec2
print("Vector Addition:", result)
```

**Output:**
```
Vector Addition: [4 6]
```

#### 2. **Scalar Multiplication**

Multiplying a vector by a scalar (a single number) scales each component:

```python
scalar = 3
vec = np.array([2, 4])

scaled_vec = scalar * vec
print("Scalar Multiplication:", scaled_vec)
```

**Output:**
```
Scalar Multiplication: [ 6 12]
```

#### 3. **Dot Product**

The dot product is a fundamental operation in linear algebra, often used to find the angle between vectors or compute projections.

```python
vec1 = np.array([1, 2, 3])
vec2 = np.array([4, 5, 6])

result = np.dot(vec1, vec2)
print("Dot Product:", result)
```

**Output:**
```
Dot Product: 32
```

Explanation:
```
(1 * 4) + (2 * 5) + (3 * 6) = 32
```

##### Distributive Property of the Dot Product
The dot product satisfies the distributive property:

$$
A \cdot (B + C) = A \cdot B + A \cdot C
$$

Example:

```python
A = np.array([1, 2])
B = np.array([3, 4])
C = np.array([5, 6])

left_side = np.dot(A, B + C)
right_side = np.dot(A, B) + np.dot(A, C)

print("Left Side (A dot (B + C)):", left_side)
print("Right Side (A dot B + A dot C):", right_side)
```

**Output:**
```
Left Side (A dot (B + C)): 26
Right Side (A dot B + A dot C): 26
```

---

#### 4. **Vector Magnitude (Length)**

The magnitude (or length) of a vector `[x, y]` is calculated using the formula:

\[ \text{magnitude} = \sqrt{x^2 + y^2} \]

In Python:

```python
vec = np.array([3, 4])
magnitude = np.linalg.norm(vec)
print("Vector Magnitude:", magnitude)
```

**Output:**
```
Vector Magnitude: 5.0
```

---

### Vector Applications

1. **Unit Vectors**: A unit vector has a magnitude of 1 and is used to represent direction. To normalize a vector (convert it to a unit vector):

```python
vec = np.array([3, 4])
unit_vector = vec / np.linalg.norm(vec)
print("Unit Vector:", unit_vector)
```

**Output:**
```
Unit Vector: [0.6 0.8]
```

2. **Projection of a Vector**: The projection of vector `A` onto vector `B` is given by:

\[ \text{Projection} = \frac{A \cdot B}{\|B\|^2} B \]

In Python:

```python
A = np.array([3, 4])
B = np.array([1, 2])

projection = (np.dot(A, B) / np.dot(B, B)) * B
print("Projection of A onto B:", projection)
```

---

### Conclusion

Vectors are a foundational concept in linear algebra and are integral to many areas of data science, machine learning, and physics. With Python and NumPy, you can easily perform vector operations, making complex mathematical computations simple and efficient. Mastering these basics will prepare you for deeper explorations into linear transformations, eigenvalues, and other advanced topics. Happy coding!

